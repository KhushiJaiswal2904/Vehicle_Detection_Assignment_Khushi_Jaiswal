{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2958cb03-97ab-4cfd-9445-439b07ea57e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\khush\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in c:\\users\\khush\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\khush\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: torch in c:\\users\\khush\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\khush\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\khush\\anaconda3\\lib\\site-packages (8.3.162)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\khush\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\khush\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\khush\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# Step 1 --> Installing required packages\n",
    "!pip install opencv-python numpy matplotlib torch torchvision ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e7ee9e-c6fa-467c-bf97-c9410a8f9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 --> Importing important libraries \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155f4984-2fff-43fb-b455-452461c49100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 --> Loading pretrained YOLOv8 model \n",
    "model = YOLO(\"yolov8n.pt\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d53fa19-24f4-4e5c-871d-9e954d44e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 --> Defining Vehicle Classes\n",
    "# Class IDs in COCO for vehicles\n",
    "TARGET_CLASSES = {'car': 2, 'motorcycle': 3, 'truck': 7}\n",
    "\n",
    "# Reverse class name mapping\n",
    "CLASS_NAMES = {2: 'car', 3: 'motorcycle', 7: 'truck'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c764d5-b1c0-49d1-b1ed-29b008261c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 --> Defining Image Processing Function\n",
    "def process_image(image_path, conf_threshold=0.5):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = model(img_rgb)[0]\n",
    "    \n",
    "    vehicle_counts = defaultdict(int)\n",
    "\n",
    "    for box in results.boxes:\n",
    "        cls_id = int(box.cls.item())\n",
    "        conf = float(box.conf.item())\n",
    "        if conf >= conf_threshold and cls_id in CLASS_NAMES:\n",
    "            label = CLASS_NAMES[cls_id]\n",
    "            vehicle_counts[label] += 1\n",
    "            # Draw box\n",
    "            xyxy = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), (0, 255, 0), 2)\n",
    "            text = f\"{label} {conf:.2f}\"\n",
    "            cv2.putText(img, text, (xyxy[0], xyxy[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    return img, vehicle_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820e9459-9cb2-49c9-a679-331bcba09959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 2 buss, 1 truck, 1 umbrella, 478.6ms\n",
      "Speed: 32.2ms preprocess, 478.6ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 3 cars, 1 traffic light, 555.6ms\n",
      "Speed: 9.7ms preprocess, 555.6ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 truck, 266.4ms\n",
      "Speed: 4.0ms preprocess, 266.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bicycle, 1 traffic light, 319.1ms\n",
      "Speed: 5.4ms preprocess, 319.1ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 5 persons, 2 cars, 2 trucks, 2 backpacks, 1 handbag, 371.9ms\n",
      "Speed: 3.7ms preprocess, 371.9ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 1 truck, 365.2ms\n",
      "Speed: 4.2ms preprocess, 365.2ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 motorcycle, 1 truck, 308.8ms\n",
      "Speed: 5.1ms preprocess, 308.8ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 bench, 321.8ms\n",
      "Speed: 3.7ms preprocess, 321.8ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 544x640 4 persons, 3 cars, 1 bus, 2 trucks, 1 refrigerator, 437.1ms\n",
      "Speed: 8.8ms preprocess, 437.1ms inference, 3.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bus, 2 trucks, 330.8ms\n",
      "Speed: 3.2ms preprocess, 330.8ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 train, 313.6ms\n",
      "Speed: 2.9ms preprocess, 313.6ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 512x640 1 person, 1 bus, 400.7ms\n",
      "Speed: 4.7ms preprocess, 400.7ms inference, 4.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x640 1 train, 1 suitcase, 465.8ms\n",
      "Speed: 9.9ms preprocess, 465.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 kite, 313.3ms\n",
      "Speed: 5.4ms preprocess, 313.3ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 608x640 4 persons, 1 bicycle, 2 cars, 2 motorcycles, 1 umbrella, 485.2ms\n",
      "Speed: 7.0ms preprocess, 485.2ms inference, 4.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 truck, 2 chairs, 318.4ms\n",
      "Speed: 3.6ms preprocess, 318.4ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 5 cars, 1 traffic light, 1 backpack, 1 umbrella, 259.7ms\n",
      "Speed: 4.3ms preprocess, 259.7ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 4 persons, 1 bench, 251.1ms\n",
      "Speed: 4.7ms preprocess, 251.1ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 bus, 1 truck, 247.2ms\n",
      "Speed: 3.5ms preprocess, 247.2ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 persons, 3 cars, 1 truck, 1 backpack, 300.1ms\n",
      "Speed: 3.0ms preprocess, 300.1ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 train, 1 microwave, 311.1ms\n",
      "Speed: 5.3ms preprocess, 311.1ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bench, 4 suitcases, 606.8ms\n",
      "Speed: 11.1ms preprocess, 606.8ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 7 persons, 2 cars, 3 buss, 1 truck, 695.1ms\n",
      "Speed: 22.1ms preprocess, 695.1ms inference, 16.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 (no detections), 434.7ms\n",
      "Speed: 15.6ms preprocess, 434.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 motorcycles, 1 truck, 1 backpack, 453.6ms\n",
      "Speed: 8.1ms preprocess, 453.6ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bus, 2 trucks, 301.9ms\n",
      "Speed: 9.0ms preprocess, 301.9ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 bicycles, 1 car, 3 motorcycles, 2 buss, 1 truck, 1 umbrella, 329.9ms\n",
      "Speed: 5.4ms preprocess, 329.9ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 bus, 602.0ms\n",
      "Speed: 28.1ms preprocess, 602.0ms inference, 3.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 car, 1 bus, 604.7ms\n",
      "Speed: 15.5ms preprocess, 604.7ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bus, 1 truck, 2 traffic lights, 399.2ms\n",
      "Speed: 6.1ms preprocess, 399.2ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 motorcycle, 1 bus, 305.8ms\n",
      "Speed: 4.2ms preprocess, 305.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 9 persons, 298.5ms\n",
      "Speed: 4.0ms preprocess, 298.5ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 truck, 412.7ms\n",
      "Speed: 5.3ms preprocess, 412.7ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 backpack, 396.8ms\n",
      "Speed: 10.5ms preprocess, 396.8ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 2 motorcycles, 1 bus, 3 trucks, 1 kite, 304.6ms\n",
      "Speed: 30.0ms preprocess, 304.6ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 1 person, 1 traffic light, 574.4ms\n",
      "Speed: 4.1ms preprocess, 574.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 9 cars, 1 bus, 2 traffic lights, 767.1ms\n",
      "Speed: 14.5ms preprocess, 767.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 5 persons, 1 bicycle, 2 buss, 1 truck, 1678.9ms\n",
      "Speed: 9.6ms preprocess, 1678.9ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 bus, 1 truck, 376.5ms\n",
      "Speed: 4.0ms preprocess, 376.5ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 1 person, 296.6ms\n",
      "Speed: 9.8ms preprocess, 296.6ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 339.9ms\n",
      "Speed: 4.9ms preprocess, 339.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 car, 285.1ms\n",
      "Speed: 3.1ms preprocess, 285.1ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 bus, 2 trucks, 572.4ms\n",
      "Speed: 2.7ms preprocess, 572.4ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 1 motorcycle, 1 bus, 1 truck, 262.5ms\n",
      "Speed: 3.2ms preprocess, 262.5ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 trucks, 1 bird, 267.6ms\n",
      "Speed: 4.0ms preprocess, 267.6ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 5 persons, 3 cars, 2 buss, 3 trucks, 1 umbrella, 1 cell phone, 269.6ms\n",
      "Speed: 2.9ms preprocess, 269.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 (no detections), 252.5ms\n",
      "Speed: 8.0ms preprocess, 252.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 448x640 1 person, 1 boat, 5 umbrellas, 1 handbag, 241.7ms\n",
      "Speed: 3.3ms preprocess, 241.7ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 bus, 1 umbrella, 1 kite, 268.7ms\n",
      "Speed: 2.6ms preprocess, 268.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 1 bus, 239.1ms\n",
      "Speed: 3.7ms preprocess, 239.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 1 bus, 1 kite, 254.8ms\n",
      "Speed: 3.3ms preprocess, 254.8ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Step 6 --> Batch Processing test images\n",
    "input_folder = r\"C:\\Users\\khush\\Downloads\\traffic_dataset\\input data\"\n",
    "output_folder = r\"C:\\Users\\khush\\Downloads\\traffic_dataset\\output data\\processed_image\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "summary_report = []\n",
    "\n",
    "for image_name in os.listdir(input_folder):\n",
    "    if image_name.lower().endswith(('.jpg', '.png')):\n",
    "        image_path = os.path.join(input_folder, image_name)\n",
    "        processed_img, counts = process_image(image_path)\n",
    "        \n",
    "        # Save annotated image\n",
    "        output_path = os.path.join(output_folder, f\"annotated_{image_name}\")\n",
    "        cv2.imwrite(output_path, processed_img)\n",
    "\n",
    "        summary_report.append({'image': image_name, 'counts': dict(counts)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277aed7-55ca-4cb4-b2c4-0ea058d0ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Processed Image\n",
    "img_show = cv2.imread(output_path)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Annotated Output\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a0128-236b-4e7b-ad71-463d7749fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 --> Generating Summary Report\n",
    "import pandas as pd\n",
    "\n",
    "summary_df = pd.DataFrame(summary_report)\n",
    "summary_df['Total'] = summary_df['counts'].apply(lambda d: sum(d.values()))\n",
    "summary_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
